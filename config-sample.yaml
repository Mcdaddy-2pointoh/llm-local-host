# HF model configs
hf_model: {
  model_name: "google/gemma-2b-it",
  device_map: "auto",
  torch_dtype: "torch.float16",
  quantization: {
    quantization_type: 'bnb',
    load_in_4_bit: True
  }
}

hf_home_path: ""
